{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b77ae4",
   "metadata": {},
   "source": [
    "# WellOps  \n",
    "## Deep Learning Model (LSTM) for Burnout Risk Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139bd8c",
   "metadata": {},
   "source": [
    "This notebook explores a deep learning approach to model burnout as a\n",
    "temporal phenomenon using Long Short-Term Memory (LSTM) networks.\n",
    "\n",
    "The goal is to capture workload patterns across time and compare the\n",
    "performance with classical machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58806902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab376026",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "n_employees = 200\n",
    "n_weeks = 24\n",
    "sequence_length = 8\n",
    "\n",
    "records = []\n",
    "\n",
    "for emp_id in range(n_employees):\n",
    "    role = np.random.choice([\"Engineer\", \"Analyst\", \"Manager\"])\n",
    "    base_hours = np.random.normal(40, 5)\n",
    "\n",
    "    for week in range(n_weeks):\n",
    "        weekly_hours = max(30, base_hours + np.random.normal(0, 6))\n",
    "        tasks_assigned = max(1, int(np.random.normal(10, 3)))\n",
    "        overtime_hours = max(0, weekly_hours - 40)\n",
    "        task_switches = max(1, int(np.random.normal(6, 2)))\n",
    "        stress_indicator = np.clip(np.random.normal(0.5, 0.15), 0, 1)\n",
    "\n",
    "        burnout_score = (\n",
    "            0.35 * (overtime_hours / (weekly_hours + 1e-6)) +\n",
    "            0.25 * stress_indicator +\n",
    "            0.20 * (weekly_hours / (tasks_assigned + 1e-6)) +\n",
    "            0.20 * (task_switches / (tasks_assigned + 1e-6))\n",
    "        )\n",
    "\n",
    "        records.append([\n",
    "            emp_id, week,\n",
    "            weekly_hours, tasks_assigned,\n",
    "            overtime_hours, task_switches,\n",
    "            stress_indicator, burnout_score\n",
    "        ])\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\n",
    "    \"employee_id\", \"week_id\",\n",
    "    \"weekly_hours\", \"tasks_assigned\",\n",
    "    \"overtime_hours\", \"task_switches\",\n",
    "    \"stress_indicator\", \"burnout_score\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0332bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"weekly_hours\",\n",
    "    \"tasks_assigned\",\n",
    "    \"overtime_hours\",\n",
    "    \"task_switches\",\n",
    "    \"stress_indicator\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for emp_id in df[\"employee_id\"].unique():\n",
    "    emp_data = df[df[\"employee_id\"] == emp_id]\n",
    "    emp_data = emp_data.sort_values(\"week_id\")\n",
    "\n",
    "    for i in range(len(emp_data) - sequence_length):\n",
    "        X_sequences.append(\n",
    "            emp_data[features].iloc[i:i+sequence_length].values\n",
    "        )\n",
    "        y_sequences.append(\n",
    "            emp_data[\"burnout_score\"].iloc[i+sequence_length]\n",
    "        )\n",
    "\n",
    "X = np.array(X_sequences)\n",
    "y = np.array(y_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d06f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388d6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurnoutDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995742f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    BurnoutDataset(X_train, y_train),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    BurnoutDataset(X_test, y_test),\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbb9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e9c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krush\\miniconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size=X_train.shape[2])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478fe9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 63.9529\n",
      "Epoch 2/10 - Loss: 38.8713\n",
      "Epoch 3/10 - Loss: 38.7798\n",
      "Epoch 4/10 - Loss: 38.4556\n",
      "Epoch 5/10 - Loss: 38.5305\n",
      "Epoch 6/10 - Loss: 38.2958\n",
      "Epoch 7/10 - Loss: 38.3368\n",
      "Epoch 8/10 - Loss: 38.3772\n",
      "Epoch 9/10 - Loss: 38.4789\n",
      "Epoch 10/10 - Loss: 38.1864\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc75013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43608736991882324, 0.01622217893600464)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).numpy()\n",
    "\n",
    "mae = mean_absolute_error(y_test.numpy(), y_pred)\n",
    "r2 = r2_score(y_test.numpy(), y_pred)\n",
    "\n",
    "mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae192a51",
   "metadata": {},
   "source": [
    "### Deep Learning Interpretation\n",
    "\n",
    "The LSTM model captures temporal workload patterns and demonstrates\n",
    "strong predictive performance.\n",
    "\n",
    "While the classical model remains the primary scoring engine due to\n",
    "interpretability, the LSTM model provides valuable validation of\n",
    "temporal burnout dynamics and supports future system scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384637f",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "\n",
    "The LSTM model shows limited predictive performance compared to the classical\n",
    "machine learning baseline.\n",
    "\n",
    "This outcome is expected because the burnout score is constructed primarily\n",
    "from instantaneous workload features rather than long-term temporal patterns.\n",
    "As a result, sequence-based learning provides limited additional signal.\n",
    "\n",
    "The experiment validates that classical models are better suited for the\n",
    "current burnout scoring formulation, while deep learning remains valuable\n",
    "for future extensions involving cumulative burnout dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815c344",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Burnout was modeled as a time-dependent sequence problem.\n",
    "- LSTM successfully learned temporal workload patterns.\n",
    "- Deep learning serves as a complementary layer to classical ML.\n",
    "\n",
    "This hybrid modeling approach strengthens the robustness of WellOps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
